# Diarum 个人 AI 助手技术方案 v2.0

**版本**: 2.0
**日期**: 2026年1月30日
**作者**: Manus AI

## 1. 修订背景

本方案在 v1.0 的基础上进行修订，旨在满足用户提出的更高灵活性和自定义能力的需求。核心调整是**移除对本地 Ollama 服务的硬性依赖**，转而采用**通用的 API + Base URL 配置方式**，并增加了对**对话历史存储**的详细设计。

## 2. 核心原则 (保持不变)

- **隐私优先**: 用户可以选择完全自托管、离线的本地模型服务。
- **架构契合**: 保持 Diarum 单体、易部署的特性。
- **资源友好**: 基础部署资源消耗低，AI 功能按需启用。
- **体验流畅**: 异步处理，交互自然。
- **高度灵活**: 用户可以自由选择和配置 AI 服务提供商。

## 3. 调整后的技术架构

新架构的核心是**解耦 AI 模型服务与 Diarum 应用本身**。Diarum 不再捆绑任何特定的 AI 服务，而是通过用户提供的配置（API Endpoint, 模型名称, API Key）来与外部或本地的 AI 服务进行交互。

### 3.1. 推荐技术栈

| 组件 | 技术选型 | 关键优势 |
| :--- | :--- | :--- |
| **向量数据库** | **chromem-go** | **嵌入式、Go 原生、零依赖**。与 Diarum 架构完美契合，无需额外服务进程，是实现简洁部署的关键。 [1] |
| **Embedding 服务** | **用户自定义 API** | **极致灵活**。支持 OpenAI, DeepSeek, 智谱, Moonshot, 以及本地 Ollama, LocalAI 等任何兼容 OpenAI API 格式的服务。 |
| **LLM 服务** | **用户自定义 API** | **按需选择**。用户可根据性能、成本和隐私需求，自由选择云服务或本地模型。 |
| **LLM 客户端** | **go-openai** | **标准、通用**。通过动态配置 `BaseURL`，可无缝连接到用户指定的任何服务。 |

### 3.2. 架构图

```mermaid
graph TD
    subgraph Diarum 应用
        A[用户界面]
        B[API 服务]
        C[PocketBase SQLite]
        D[AI 服务层]
        E[chromem-go 向量库]
        F[配置管理]
    end

    subgraph 用户配置的外部服务
        G[Embedding API<br/>(用户配置 Base URL)]
        H[LLM API<br/>(用户配置 Base URL)]
    end

    A -- 设置 --> F
    F -- 读取配置 --> D
    A -- 对话 --> B
    B -- 调用 --> D
    D -- 存储向量 --> E
    D -- 生成 Embedding --> G
    D -- 生成回答 --> H
    B -- 读写日记 --> C
    D -- 读取日记 --> C
```

### 3.3. 数据流

- **索引流程**: 当用户保存日记时，Diarum 的 AI 服务层会读取用户配置，调用指定的 Embedding API 将日记文本向量化，并将结果存入 `chromem-go` 数据库。
- **检索流程**: 当用户提问时，AI 服务层同样根据用户配置，分别调用 Embedding API 对问题进行向量化，在 `chromem-go` 中检索相关日记，然后调用 LLM API 将问题和上下文整合成 Prompt 以生成回答。

## 4. 用户配置方案

为了降低用户的配置门槛，我们设计了一套包含预设模板和详细自定义选项的配置界面。

### 4.1. 界面设计

在 Diarum 的设置中新增"AI 助手"模块，主要包含：

1.  **主开关**: 一键启用或禁用 AI 功能。
2.  **快速配置模板**: 提供“OpenAI”、“DeepSeek”、“本地 Ollama”等预设选项，用户选择后可自动填充大部分配置。
3.  **自定义配置**: 分别为“向量化 (Embedding) 模型”和“对话模型 (LLM)”提供独立的配置区域，用户需填写 `API Base URL`, `模型名称`, 和 `API Key`。
4.  **连接测试**: 每个配置区域都提供“测试连接”按钮，后端会发送一个简单的请求来验证用户的配置是否正确有效。
5.  **高级设置**: 允许用户调整如“检索日记数量”、“最大生成 Token 数”、“温度 (Temperature)”等参数，并提供是否“保存对话历史”的开关。

### 4.2. 配置存储与安全

- **存储**: AI 配置信息将存储在 PocketBase 的一个新集合 `ai_settings` 中，与用户关联。
- **安全**: 为了保护用户隐私，所有 `API Key` 在存入数据库前都将**使用 AES-256-GCM 进行加密**。密钥由 Diarum 应用管理，确保数据安全。

## 5. 对话历史存储方案

为了提供连续的对话体验和方便用户回顾，我们设计了可选的对话历史存储功能。

### 5.1. 数据库设计

在 PocketBase 中创建两个新的集合：

1.  **`ai_conversations`**: 用于存储每个独立的对话会话。包含会话标题、摘要、消息数、最后更新时间等字段。
2.  **`ai_messages`**: 用于存储每一条具体的消息。包含所属会话 ID、角色（用户/助手）、消息内容、引用的日记 ID 列表等字段。

### 5.2. 功能设计

- **会话管理**: 用户可以创建新对话、查看历史对话列表、搜索、重命名、归档和删除会话。
- **上下文记忆**: 在同一个会话中，AI 会自动加载最近的几条消息作为上下文，以实现连续对话。通过限制上下文窗口大小（如最近10条消息或4000个Token）来平衡效果与成本。
- **引用追溯**: AI 的回答会附带其参考的日记链接，用户可以点击查看原文，确保信息的可信度和透明度。
- **数据导出**: 用户可以将会话导出为 Markdown 或 JSON 格式，方便备份和在其他地方使用。

### 5.3. 隐私与控制

- **用户可选**: 用户可以在设置中随时开启或关闭对话历史存储功能。
- **数据清理**: 提供手动和自动清理功能，例如“删除30天前的对话”，让用户完全掌控自己的数据。
- **访问隔离**: 严格的数据库访问规则确保每个用户只能访问自己的对话历史。

## 6. 实施方案

### 6.1. 部署

- **简化部署**: 由于移除了 Ollama 的捆绑，Diarum 的 Docker 部署将回归到单容器模式，降低了对用户服务器的资源要求。
- **文档引导**: 提供详细的文档，指导用户如何根据自己的需求选择和配置 AI 服务，包括如何自行部署 Ollama 等本地服务。

### 6.2. 后端改造 (Go)

1.  **配置管理**: 实现 `ai_settings` 的增删改查，包括 API Key 的加解密逻辑。
2.  **动态客户端**: 修改 AI 服务层，使其能够根据用户的配置动态创建 `go-openai` 客户端实例。
3.  **API 调整**: 调整 `/api/ai/chat` 接口，使其支持会话 ID，并实现对话历史的读写逻辑。
4.  **新增会话管理 API**: 创建用于管理会话（增删改查）的 RESTful API。

### 6.3. 前端改造 (Svelte)

1.  **开发配置页面**: 实现 v2.0 设计的“AI 助手”配置界面，包括模板选择、自定义输入、连接测试等功能。
2.  **开发会话界面**: 在 AI 助手页面左侧增加一个可伸缩的侧边栏，用于展示和管理对话会话列表。
3.  **更新聊天组件**: 增加引用追溯的显示逻辑，并在界面上提供会话管理的操作入口。

## 7. 结论

方案 v2.0 在保持 v1.0 核心优势（嵌入式、架构契合）的基础上，通过**将 AI 服务配置完全交由用户自定义**，极大地提升了方案的**灵活性和普适性**。无论是追求极致隐私的本地部署爱好者，还是希望获得最佳性能的云服务用户，都能在这套统一的架构下找到满足自己需求的解决方案。

同时，**精细化的对话历史管理功能**的设计，使得 AI 助手不再是“一次性”的工具，而是能够沉淀知识、提供连续性思考支持的智能伙伴，进一步增强了 Diarum 的核心价值。

---

## 参考文献

[1] Philipp Gillé. (2024). *Embeddable vector database for Go with Chroma-like interface and zero third-party dependencies*. GitHub. Retrieved from https://github.com/philippgille/chromem-go
